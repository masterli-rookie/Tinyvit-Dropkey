{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import (accuracy_score, f1_score, confusion_matrix, \n",
    "                           classification_report, precision_score, recall_score)\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Model imports\n",
    "import wandb\n",
    "from ptflops import get_model_complexity_info\n",
    "from models.tiny_vit import (tiny_vit_5m_224, tiny_vit_11m_224, \n",
    "                           tiny_vit_21m_224, tiny_vit_21m_384, tiny_vit_21m_512)\n",
    "\n",
    "# ==================== Rest of your code remains the same ====================\n",
    "class TimeTracker:\n",
    "    \"\"\"训练过程时间追踪器\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch_times = []\n",
    "        self.batch_times = []\n",
    "        self.epoch_start_time = None\n",
    "        self.batch_start_time = None\n",
    "    \n",
    "    def start_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "    \n",
    "    def end_epoch(self):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        return epoch_time\n",
    "    \n",
    "    def start_batch(self):\n",
    "        self.batch_start_time = time.time()\n",
    "    \n",
    "    def end_batch(self):\n",
    "        batch_time = time.time() - self.batch_start_time\n",
    "        self.batch_times.append(batch_time)\n",
    "        return batch_time\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"获取时间统计信息\"\"\"\n",
    "        if not self.epoch_times:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'total_epoch_time': sum(self.epoch_times),\n",
    "            'avg_epoch_time': np.mean(self.epoch_times),\n",
    "            'median_epoch_time': np.median(self.epoch_times),\n",
    "            'min_epoch_time': np.min(self.epoch_times),\n",
    "            'max_epoch_time': np.max(self.epoch_times),\n",
    "            'avg_batch_time': np.mean(self.batch_times) if self.batch_times else 0,\n",
    "            'total_batch_time': sum(self.batch_times) if self.batch_times else 0\n",
    "        }\n",
    "\n",
    "def get_model_stats(model, input_size=(3, 224, 224)):\n",
    "    \"\"\"获取模型FLOPs和参数数量\"\"\"\n",
    "    # 确保输入是4D格式 (batch_size, channels, height, width)\n",
    "    if len(input_size) == 3:\n",
    "        input_size = (1,) + input_size  # 添加batch维度\n",
    "    \n",
    "    try:\n",
    "        # 修正输入维度问题\n",
    "        if len(input_size) == 4 and input_size[0] == 1:\n",
    "            # 如果已经是(1,3,224,224)格式，则直接使用\n",
    "            pass\n",
    "        elif len(input_size) == 3:\n",
    "            input_size = (1,) + input_size\n",
    "        \n",
    "        # 处理TinyViT的特殊输入要求\n",
    "        if hasattr(model, 'backbone'):\n",
    "            # 创建一个包装器函数来适配TinyViT\n",
    "            def flops_model(x):\n",
    "                return model.backbone(x)\n",
    "            \n",
    "            macs, params = get_model_complexity_info(\n",
    "                flops_model, \n",
    "                input_size, \n",
    "                as_strings=False, \n",
    "                print_per_layer_stat=False,\n",
    "                ignore_modules=[nn.Dropout, nn.BatchNorm2d, nn.LayerNorm]\n",
    "            )\n",
    "        else:\n",
    "            macs, params = get_model_complexity_info(\n",
    "                model, \n",
    "                input_size, \n",
    "                as_strings=False, \n",
    "                print_per_layer_stat=False,\n",
    "                ignore_modules=[nn.Dropout, nn.BatchNorm2d, nn.LayerNorm]\n",
    "            )\n",
    "        \n",
    "        # 转换为百万单位\n",
    "        flops = macs * 2  # MACs转换为FLOPs (1 MAC = 2 FLOPs)\n",
    "        flops_m = flops / 1e6\n",
    "        params_m = params / 1e6\n",
    "        \n",
    "        return {\n",
    "            'flops': flops,\n",
    "            'flops_m': flops_m,\n",
    "            'params': params,\n",
    "            'params_m': params_m,\n",
    "            'flops_str': f\"{flops_m:.2f}M\",\n",
    "            'params_str': f\"{params_m:.2f}M\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating FLOPs: {e}\")\n",
    "        # 只计算参数数量作为后备方案\n",
    "        params = sum(p.numel() for p in model.parameters())\n",
    "        params_m = params / 1e6\n",
    "        \n",
    "        return {\n",
    "            'flops': None,\n",
    "            'flops_m': None,\n",
    "            'params': params,\n",
    "            'params_m': params_m,\n",
    "            'flops_str': \"N/A\",\n",
    "            'params_str': f\"{params_m:.2f}M\"\n",
    "        }\n",
    "\n",
    "def measure_latency(model, input_size=(3, 224, 224), repetitions=100, warmup=10):\n",
    "    \"\"\"测量模型推理延迟\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    # 确保输入是4D格式 (batch_size, channels, height, width)\n",
    "    if len(input_size) == 3:\n",
    "        input_size = (1,) + input_size\n",
    "    \n",
    "    dummy_input = torch.randn(input_size).to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model(dummy_input)\n",
    "    \n",
    "    # 同步GPU操作\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # 测量时间\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(repetitions):\n",
    "            start = time.time()\n",
    "            _ = model(dummy_input)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            timings.append(end - start)\n",
    "    \n",
    "    # 转换为毫秒\n",
    "    timings = np.array(timings) * 1000\n",
    "    return {\n",
    "        'latency_mean': np.mean(timings),\n",
    "        'latency_median': np.median(timings),\n",
    "        'latency_min': np.min(timings),\n",
    "        'latency_max': np.max(timings),\n",
    "        'latency_std': np.std(timings),\n",
    "        'fps': 1000 / np.mean(timings)\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================== Enhanced Components ====================\n",
    "class DropKeyAttention(nn.Module):\n",
    "    \"\"\"带DropKey的注意力机制改进版\"\"\"\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0., drop_key_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        \n",
    "        # DropKey specific\n",
    "        self.drop_key = nn.Dropout(drop_key_prob)\n",
    "        self.drop_key_prob = drop_key_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        # 关键修改：在softmax前应用DropKey\n",
    "        if self.training and self.drop_key_prob > 0:\n",
    "            attn = self.drop_key(attn)\n",
    "            attn = attn / (attn.sum(dim=-1, keepdim=True) + 1e-6)  # 重新归一化\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class AdvancedMixupCutmix:\n",
    "    \"\"\"增强版混合策略，动态选择Mixup或CutMix\"\"\"\n",
    "    def __init__(self, mixup_alpha=0.8, cutmix_alpha=1.0, switch_prob=0.5):\n",
    "        self.mixup_beta = torch.distributions.Beta(mixup_alpha, mixup_alpha)\n",
    "        self.cutmix_beta = torch.distributions.Beta(cutmix_alpha, cutmix_alpha)\n",
    "        self.switch_prob = switch_prob\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        if random.random() < self.switch_prob:  # CutMix模式\n",
    "            lam = self.cutmix_beta.sample().item()\n",
    "            bbx1, bby1, bbx2, bby2 = self.rand_bbox(x.size(), lam)\n",
    "            x[:, :, bbx1:bbx2, bby1:bby2] = x.flip(0)[:, :, bbx1:bbx2, bby1:bby2]\n",
    "            # 调整lambda以匹配实际混合比例\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "            return x, (y, y.flip(0), lam)\n",
    "        else:  # Mixup模式\n",
    "            lam = self.mixup_beta.sample().item()\n",
    "            return lam*x + (1-lam)*x.flip(0), (y, y.flip(0), lam)\n",
    "\n",
    "    def rand_bbox(self, size, lam):\n",
    "        W, H = size[2], size[3]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "class SmartRandomErasing:\n",
    "    \"\"\"改进版随机擦除，自动适应张量/PIL输入\"\"\"\n",
    "    def __init__(self, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, mode='pixel'):\n",
    "        self.p = p\n",
    "        self.scale = scale\n",
    "        self.ratio = ratio\n",
    "        self.value = value\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.p:\n",
    "            return img\n",
    "\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            return self._erase_tensor(img)\n",
    "        else:  # PIL Image\n",
    "            return self._erase_pil(img)\n",
    "\n",
    "    def _erase_tensor(self, img):\n",
    "        C, H, W = img.shape\n",
    "        area = H * W\n",
    "\n",
    "        for _ in range(10):\n",
    "            erase_area = random.uniform(*self.scale) * area\n",
    "            aspect_ratio = random.uniform(*self.ratio)\n",
    "\n",
    "            h = int(round(math.sqrt(erase_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(erase_area / aspect_ratio)))\n",
    "\n",
    "            if h < H and w < W:\n",
    "                i = random.randint(0, H - h)\n",
    "                j = random.randint(0, W - w)\n",
    "                \n",
    "                if self.mode == 'pixel':\n",
    "                    v = torch.rand(C, h, w, dtype=img.dtype, device=img.device)\n",
    "                else:\n",
    "                    v = torch.rand(C, 1, 1, dtype=img.dtype, device=img.device).expand(-1, h, w)\n",
    "                \n",
    "                img[:, i:i+h, j:j+w] = v\n",
    "                return img\n",
    "        return img\n",
    "\n",
    "    def _erase_pil(self, img):\n",
    "        img_np = np.array(img)\n",
    "        H, W, C = img_np.shape\n",
    "        area = H * W\n",
    "\n",
    "        for _ in range(10):\n",
    "            erase_area = random.uniform(*self.scale) * area\n",
    "            aspect_ratio = random.uniform(*self.ratio)\n",
    "\n",
    "            h = int(round(math.sqrt(erase_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(erase_area / aspect_ratio)))\n",
    "\n",
    "            if h < H and w < W:\n",
    "                i = random.randint(0, H - h)\n",
    "                j = random.randint(0, W - w)\n",
    "                \n",
    "                if self.mode == 'pixel':\n",
    "                    v = np.random.randint(0, 256, (h, w, C))\n",
    "                else:\n",
    "                    v = np.random.randint(0, 256, (1, 1, C))\n",
    "                    v = np.tile(v, (h, w, 1))\n",
    "                \n",
    "                img_np[i:i+h, j:j+w, :] = v\n",
    "                return transforms.ToPILImage()(img_np.transpose(2, 0, 1))\n",
    "        return img\n",
    "\n",
    "# ==================== Enhanced TinyViT ====================\n",
    "\n",
    "class EnhancedTinyViT(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, drop_key_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.backbone = base_model\n",
    "        self._replace_attention(drop_key_prob)\n",
    "        \n",
    "        # 动态获取特征维度\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224).to(next(base_model.parameters()).device)\n",
    "            features = self.backbone(dummy_input)\n",
    "            feature_dim = features.shape[-1]\n",
    "        \n",
    "        self.head = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "    def _replace_attention(self, drop_key_prob, module=None):\n",
    "        \"\"\"递归替换所有注意力层，适配TinyViT的实际结构\"\"\"\n",
    "        if module is None:\n",
    "            module = self.backbone\n",
    "            \n",
    "        for name, child in module.named_children():\n",
    "            if hasattr(child, 'attn') and isinstance(child.attn, nn.Module):\n",
    "                # 获取原始注意力层参数\n",
    "                dim = child.attn.qkv.in_features\n",
    "                num_heads = child.attn.num_heads\n",
    "                qkv_bias = child.attn.qkv.bias is not None\n",
    "                \n",
    "                # 安全获取dropout参数\n",
    "                attn_drop = getattr(child.attn, 'attn_drop', nn.Dropout(0.)).p\n",
    "                proj_drop = getattr(child.attn, 'proj_drop', nn.Dropout(0.)).p\n",
    "                \n",
    "                # 替换为带DropKey的注意力层\n",
    "                child.attn = DropKeyAttention(\n",
    "                    dim=dim,\n",
    "                    num_heads=num_heads,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    attn_drop=attn_drop,\n",
    "                    proj_drop=proj_drop,\n",
    "                    drop_key_prob=drop_key_prob\n",
    "                )\n",
    "            \n",
    "            # 递归处理子模块\n",
    "            if isinstance(child, nn.ModuleList) or isinstance(child, nn.Sequential):\n",
    "                for sub_module in child:\n",
    "                    self._replace_attention(drop_key_prob, sub_module)\n",
    "            elif isinstance(child, nn.Module):\n",
    "                self._replace_attention(drop_key_prob, child)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.head(features)\n",
    "        \n",
    "class Visualizer:\n",
    "    @staticmethod\n",
    "    def cnf_matrix_plotter(cm, classes, cmap=plt.cm.Blues, filename='confusion_matrix.pdf'):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title('Confusion Matrix', fontsize=14, pad=20)\n",
    "        plt.colorbar()\n",
    "\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45, fontsize=12)\n",
    "        plt.yticks(tick_marks, classes, rotation=45, fontsize=12)\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, f\"{cm[i, j]}\",\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                     fontsize=12)\n",
    "\n",
    "        plt.ylabel('True label', fontsize=14)\n",
    "        plt.xlabel('Predicted label', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod \n",
    "    def plot_tsne(features, labels, class_names, filename='tsne.pdf'):\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=300)\n",
    "        features_tsne = tsne.fit_transform(features)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            mask = labels == i\n",
    "            plt.scatter(features_tsne[mask, 0], features_tsne[mask, 1],\n",
    "                        c=[colors[i]], label=class_name, s=50, alpha=0.6)\n",
    "\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.xlabel('t-SNE 1', fontsize=14)\n",
    "        plt.ylabel('t-SNE 2', fontsize=14)\n",
    "        plt.legend(loc='upper right', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_training_metrics(history, filename='training_metrics.pdf'):\n",
    "        \"\"\"绘制训练指标曲线\"\"\"\n",
    "        epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "        # Loss曲线\n",
    "        ax1.plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train')\n",
    "        ax1.plot(epochs, history['val_loss'], 'r-', linewidth=2, label='Validation')\n",
    "        ax1.set_title('Training and Validation Loss', fontsize=14)\n",
    "        ax1.set_xlabel('Epoch', fontsize=12)\n",
    "        ax1.set_ylabel('Loss', fontsize=12)\n",
    "        ax1.legend(fontsize=12)\n",
    "        ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Accuracy曲线\n",
    "        ax2.plot(epochs, history['train_acc'], 'b-', linewidth=2, label='Train')\n",
    "        ax2.plot(epochs, history['val_acc'], 'r-', linewidth=2, label='Validation')\n",
    "        ax2.set_title('Training and Validation Accuracy', fontsize=14)\n",
    "        ax2.set_xlabel('Epoch', fontsize=12)\n",
    "        ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "        ax2.legend(fontsize=12)\n",
    "        ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # F1 Score曲线\n",
    "        ax3.plot(epochs, history['train_f1'], 'b-', linewidth=2, label='Train')\n",
    "        ax3.plot(epochs, history['val_f1'], 'r-', linewidth=2, label='Validation')\n",
    "        ax3.set_title('Training and Validation F1 Score', fontsize=14)\n",
    "        ax3.set_xlabel('Epoch', fontsize=12)\n",
    "        ax3.set_ylabel('F1 Score', fontsize=12)\n",
    "        ax3.legend(fontsize=12)\n",
    "        ax3.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # 学习率曲线\n",
    "        ax4.plot(epochs, history['lr'], 'g-', linewidth=2, label='Learning Rate')\n",
    "        ax4.set_title('Learning Rate Schedule', fontsize=14)\n",
    "        ax4.set_xlabel('Epoch', fontsize=12)\n",
    "        ax4.set_ylabel('Learning Rate', fontsize=12)\n",
    "        ax4.legend(fontsize=12)\n",
    "        ax4.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_roc_curve(y_true, y_score, class_names, filename='roc_curve.pdf'):\n",
    "        \"\"\"绘制多类ROC曲线\"\"\"\n",
    "        y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "        n_classes = y_true_bin.shape[1]\n",
    "\n",
    "        # 计算每个类的ROC曲线和AUC\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # 计算微平均ROC曲线和AUC\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # 绘制所有ROC曲线\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = cycle(['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])\n",
    "        \n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                     label='{0} (AUC = {1:0.2f})'.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=14)\n",
    "        plt.ylabel('True Positive Rate', fontsize=14)\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, pad=20)\n",
    "        plt.legend(loc=\"lower right\", fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_class_distribution(labels, class_names, filename='class_distribution.pdf'):\n",
    "        \"\"\"绘制类别分布直方图\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        counts = np.bincount(labels)\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(class_names)))\n",
    "        \n",
    "        bars = plt.bar(class_names, counts, color=colors)\n",
    "        plt.title('Class Distribution', fontsize=16, pad=20)\n",
    "        plt.xlabel('Class', fontsize=14)\n",
    "        plt.ylabel('Count', fontsize=14)\n",
    "        plt.xticks(rotation=45, fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        \n",
    "        # 在柱子上添加数值标签\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_interactive_metrics(history, filename='interactive_metrics.html'):\n",
    "        \"\"\"创建交互式训练指标图\"\"\"\n",
    "        epochs = list(range(1, len(history['train_loss']) + 1))\n",
    "        \n",
    "        fig = make_subplots(rows=2, cols=2,\n",
    "                           subplot_titles=(\"Training and Validation Loss\",\n",
    "                                          \"Training and Validation Accuracy\",\n",
    "                                          \"Training and Validation F1 Score\",\n",
    "                                          \"Learning Rate Schedule\"))\n",
    "        \n",
    "        # Loss曲线\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['train_loss'], name=\"Train Loss\", line=dict(color='blue')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['val_loss'], name=\"Validation Loss\", line=dict(color='red')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Accuracy曲线\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['train_acc'], name=\"Train Accuracy\", line=dict(color='blue')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['val_acc'], name=\"Validation Accuracy\", line=dict(color='red')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # F1 Score曲线\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['train_f1'], name=\"Train F1\", line=dict(color='blue')),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['val_f1'], name=\"Validation F1\", line=dict(color='red')),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # 学习率曲线\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history['lr'], name=\"Learning Rate\", line=dict(color='green')),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # 更新布局\n",
    "        fig.update_layout(height=800, width=1000, title_text=\"Training Metrics\", showlegend=True)\n",
    "        fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"Epoch\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Epoch\", row=2, col=2)\n",
    "        \n",
    "        fig.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Accuracy\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"F1 Score\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Learning Rate\", row=2, col=2)\n",
    "        \n",
    "        fig.write_html(filename)\n",
    "\n",
    "# ==================== Training Pipeline ====================\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, scaler, config, epoch, time_tracker=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        if time_tracker is not None:\n",
    "            time_tracker.start_batch()\n",
    "            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast(device_type='cuda'):  # 更新后的 API\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # 保存预测结果和真实标签\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        if time_tracker is not None:\n",
    "            batch_time = time_tracker.end_batch()\n",
    "            pbar.set_postfix({\n",
    "                'Loss': total_loss/(batch_idx+1), \n",
    "                'Acc': 100.*correct/total,\n",
    "                'BatchTime': f'{batch_time:.3f}s'\n",
    "            })\n",
    "        else:\n",
    "            pbar.set_postfix({\n",
    "                'Loss': total_loss/(batch_idx+1), \n",
    "                'Acc': 100.*correct/total\n",
    "            })\n",
    "    \n",
    "    # 计算训练集的 F1 分数（确保 all_targets 和 all_preds 非空）\n",
    "    if len(all_targets) > 0 and len(all_preds) > 0:\n",
    "        train_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    else:\n",
    "        train_f1 = 0.0  # 默认值\n",
    "    \n",
    "    return {\n",
    "        'train_loss': total_loss/len(train_loader),\n",
    "        'train_acc': correct/total,\n",
    "        'train_f1': train_f1  # 确保包含此键\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================== 验证函数 ====================\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # 计算混淆矩阵及其衍生指标\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    \n",
    "    # 计算每个类别的指标\n",
    "    class_precision = precision_score(all_targets, all_preds, average=None)\n",
    "    class_recall = recall_score(all_targets, all_preds, average=None)\n",
    "    class_f1 = f1_score(all_targets, all_preds, average=None)\n",
    "    \n",
    "    # 打印详细的分类报告\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, target_names=val_loader.dataset.classes))\n",
    "    \n",
    "    # 打印混淆矩阵衍生指标\n",
    "    print(\"\\nConfusion Matrix Derived Metrics:\")\n",
    "    print(f\"{'Class':<15}{'Precision':>12}{'Recall':>12}{'F1-score':>12}\")\n",
    "    for i, class_name in enumerate(val_loader.dataset.classes):\n",
    "        print(f\"{class_name:<15}{class_precision[i]:>12.4f}{class_recall[i]:>12.4f}{class_f1[i]:>12.4f}\")\n",
    "    print(f\"{'Macro Avg':<15}{precision:>12.4f}{recall:>12.4f}{f1:>12.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'val_loss': total_loss/len(val_loader),\n",
    "        'val_acc': accuracy,\n",
    "        'val_f1': f1,\n",
    "        'val_precision': precision,\n",
    "        'val_recall': recall,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# ==================== 主函数 ====================\n",
    "def main():\n",
    "    # 配置参数\n",
    "    config = {\n",
    "        'model_name': 'tiny_vit_5m_224',\n",
    "        'num_classes': 6,\n",
    "        'drop_key_prob': 0.1,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 64,\n",
    "        'lr': 2e-4,\n",
    "        'weight_decay': 0.05,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # 初始化\n",
    "    torch.manual_seed(config['seed'])\n",
    "    np.random.seed(config['seed'])\n",
    "    random.seed(config['seed'])\n",
    "    time_tracker = TimeTracker()\n",
    "    \n",
    "    # 数据增强和加载\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder('soil/train', train_transform)\n",
    "    val_dataset = datasets.ImageFolder('soil/val', val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 模型初始化 - 添加这部分代码\n",
    "    base_model = tiny_vit_5m_224(pretrained=True).to(device)\n",
    "    model = EnhancedTinyViT(base_model, config['num_classes'], config['drop_key_prob']).to(device)\n",
    "    \n",
    "    # 训练组件 - 添加这部分代码\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scaler = GradScaler()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])\n",
    "    \n",
    "    # 训练循环\n",
    "    best_acc = 0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'train_f1': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        time_tracker.start_epoch()\n",
    "        \n",
    "        # 训练和验证\n",
    "        train_metrics = train_one_epoch(model, train_loader, optimizer, criterion, scaler, config, epoch, time_tracker)\n",
    "        val_metrics = validate(model, val_loader, criterion)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 记录历史数据\n",
    "        history['train_loss'].append(train_metrics['train_loss'])\n",
    "        history['val_loss'].append(val_metrics['val_loss'])\n",
    "        history['train_acc'].append(train_metrics['train_acc'])\n",
    "        history['val_acc'].append(val_metrics['val_acc'])\n",
    "        history['train_f1'].append(train_metrics['train_f1'])\n",
    "        history['val_f1'].append(val_metrics['val_f1'])\n",
    "        history['val_precision'].append(val_metrics['val_precision'])  # 新增\n",
    "        history['val_recall'].append(val_metrics['val_recall'])        # 新增\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_metrics['val_acc'] > best_acc:\n",
    "            best_acc = val_metrics['val_acc']\n",
    "            torch.save(model.state_dict(), f'best_model_{best_acc:.4f}.pth')\n",
    "        \n",
    "        # 打印日志（增强版）\n",
    "        epoch_time = time_tracker.end_epoch()\n",
    "        print(f\"\\nEpoch {epoch}/{config['epochs']} Summary:\")\n",
    "        print(f\"Train Loss: {train_metrics['train_loss']:.4f} | Train Acc: {train_metrics['train_acc']:.4f} | Train F1: {train_metrics['train_f1']:.4f}\")\n",
    "        print(f\"Val Loss: {val_metrics['val_loss']:.4f} | Val Acc: {val_metrics['val_acc']:.4f}\")\n",
    "        print(f\"Val Precision: {val_metrics['val_precision']:.4f} | Val Recall: {val_metrics['val_recall']:.4f} | Val F1: {val_metrics['val_f1']:.4f}\")\n",
    "        print(f\"Time: {epoch_time:.2f}s | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    \n",
    "    # 训练结束后生成可视化结果...(保持不变)\n",
    "    \n",
    "    # 最终输出\n",
    "    print(f\"\\nTraining completed. Best Val Acc: {best_acc:.4f}\")\n",
    "    time_stats = time_tracker.get_stats()\n",
    "    print(f\"\\nTime Statistics:\")\n",
    "    print(f\"Total training time: {time_stats['total_epoch_time']:.2f}s\")\n",
    "    print(f\"Average epoch time: {time_stats['avg_epoch_time']:.2f}s\")\n",
    "    print(f\"Median epoch time: {time_stats['median_epoch_time']:.2f}s\")\n",
    "    print(f\"Fastest epoch: {time_stats['min_epoch_time']:.2f}s\")\n",
    "    print(f\"Slowest epoch: {time_stats['max_epoch_time']:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    main()  # 移除了wandb.init()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
